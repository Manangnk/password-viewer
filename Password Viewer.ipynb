{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.dataset import *\n",
    "from fastai.learner import *\n",
    "from fastai.metrics import *\n",
    "from fastai.core import *\n",
    "from fastai.model import *\n",
    "from fastai.lm_rnn import *\n",
    "from collections import *\n",
    "from fastai.conv_learner import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize(\n",
    "   mean=[28.95067, 28.9055 , 28.72874],\n",
    "   std=[26.60848, 26.28552, 25.77563]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = torchvision.transforms.Compose([\n",
    "   torchvision.transforms.Resize(256),\n",
    "   torchvision.transforms.CenterCrop(240),\n",
    "   torchvision.transforms.ToTensor(),\n",
    "   #normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PasswordDataset(Dataset):\n",
    "    def __init__(self, files, ys):\n",
    "        self.files = files\n",
    "        self.ys = ys\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.files[idx], self.ys[idx])\n",
    "        out = (preprocess(PIL.Image.open(self.files[idx]))/255).float().cuda()[:3], self.ys[idx].long().cuda()\n",
    "        return out\n",
    "        #return torch.Tensor(np.asarray(PIL.Image.open(self.files[idx]))/255).float().cuda()[:, :, :3],X\n",
    "        \n",
    "    \n",
    "    def __len__(self): return len(self.ys)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_files(cls, img_path, y_path, cv_idxs):\n",
    "        files = np.array(sorted(glob(img_path), key=lambda x: int(re.findall('\\d+', x)[0])))\n",
    "\n",
    "        ys = None\n",
    "        \n",
    "        with open(y_path) as f:\n",
    "            raw = f.read().split(\"\\n\")\n",
    "            ys = np.array([int(x) for x in raw if x != ''])\n",
    "        \n",
    "        mask = np.zeros(len(files), dtype='bool')\n",
    "        print(len(files))\n",
    "        mask[cv_idxs] = True\n",
    "        val_where = list(mask)\n",
    "        trn_where = list(~mask)\n",
    "\n",
    "        #trn_where = ~mask\n",
    "        return cls(files[trn_where], torch.Tensor(ys[trn_where])), cls(files[val_where], torch.tensor(ys[val_where]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = \"/home/robert/Documents/typingviewer/data/vidya/image-*.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_path = \"/home/robert/Documents/typingviewer/data/y2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(glob(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_idxs = get_cv_idxs(dataset_size, val_pct=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1424,  111, 1841,  968,  415, 1780,   70,  530,  617, 1033, 1394,  949, 1085,  128,  367, 1894, 1214,\n",
       "        730,  374, 1329,  275,  861, 1189, 1273,  212,  777,  135, 1465, 1653, 1265,  654,  857, 1538, 1497,\n",
       "        231, 1283, 1304, 1289,  593, 1735,  585,  324,  366,  555, 1550, 1690,  414, 1364,   99, 1383, 1228,\n",
       "       1026, 1435,  237,  289, 1083, 1745,  382,  806, 1477, 1658, 1073,  838, 1870,  297, 1261, 1862, 1313,\n",
       "        677, 1347, 1475, 1268, 1895,   65, 1058, 1393, 1672,  916,   29,  610, 1677,  707, 1298, 1774,  572,\n",
       "       1592,  331, 1568, 1562,  485, 1414,  413, 1762, 1284,  453,  438,  964, 1029, 1667,  694,  322, 1350,\n",
       "       1680,  196,  936,  596,  120, 1374, 1611,  759,  109,  305, 1829, 1454, 1843,  755,  344,  427,  561,\n",
       "       1133,  845, 1623, 1839, 1594, 1317,  613,  979, 1124,  788,  710,  611, 1331,  514, 1164,  251,  976,\n",
       "       1898,  480,  527,  239, 1606, 1582,  932,  254, 1688, 1222, 1055, 1734, 1567,  518, 1211, 1433, 1425,\n",
       "        700,   23,  306,   63,  425,  303, 1580,  715,  429, 1732,  921,  188, 1432, 1251, 1847, 1296, 1808,\n",
       "        859,  554,  416, 1552, 1067,  602, 1301,  115, 1489,  765,  526,  865, 1389,  591,  720, 1784,  420,\n",
       "       1466,  173, 1605])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908\n"
     ]
    }
   ],
   "source": [
    "trn_ds, val_ds = PasswordDataset.from_files(image_paths, y_path, cv_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({10.0: 204,\n",
       "         2.0: 129,\n",
       "         5.0: 158,\n",
       "         1.0: 114,\n",
       "         4.0: 192,\n",
       "         7.0: 162,\n",
       "         8.0: 217,\n",
       "         0.0: 160,\n",
       "         9.0: 145,\n",
       "         6.0: 139,\n",
       "         3.0: 98})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([x.item() for x in trn_ds.ys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.00000e-03 *\n",
       "        [[[ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          ...,\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691]],\n",
       " \n",
       "         [[ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          ...,\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691]],\n",
       " \n",
       "         [[ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3537,  0.3537,  0.3537],\n",
       "          ...,\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691],\n",
       "          [ 0.3537,  0.3537,  0.3537,  ...,  0.3691,  0.3691,  0.3691]]], device='cuda:0'),\n",
       " tensor(10, device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = torch.utils.data.DataLoader(trn_ds, batch_size=bs)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, out_dim=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3))\n",
    "        self.fc = nn.Linear(26*26*32, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        #print(out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "myConv = SingleModel(ConvNet().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ModelData('model', trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 240, 240])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsigned = np.array(np.clip(to_np(trn_ds[0][0]*256), 0, 255), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0a37b8d8d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.moveaxis(unsigned, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "myConv = SingleModel(ConvnetBuilder(resnet18, 200, False, False).model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mp): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (9): Flatten()\n",
       "  (10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Dropout(p=0.25)\n",
       "  (12): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (13): ReLU()\n",
       "  (14): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Dropout(p=0.5)\n",
       "  (16): Linear(in_features=512, out_features=200, bias=True)\n",
       "  (17): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myConv.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#myConv.model[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner = Learner(md, myConv, opt_fn=optim.Adam, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#learner.fit(1*1e-3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PasswordStatefulLSTM(nn.Module):\n",
    "    def __init__(self, bs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_final_width = 100\n",
    "        self.number_rnn_layers = 1\n",
    "        self.rnn_hidden_count = 20\n",
    "        self.output_size = 11\n",
    "        \n",
    "        self.myConv = ConvNet(out_dim=11)\n",
    "        \n",
    "        self.convToLSTM = nn.Linear(115200, self.cnn_final_width)\n",
    "        #self.convToLSTMBn = nn.BatchNorm1d(115200)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.cnn_final_width, self.rnn_hidden_count, self.number_rnn_layers, dropout=0.2)\n",
    "        self.l_out = nn.Linear(self.rnn_hidden_count, self.output_size)\n",
    "        self.final_out = nn.Linear(self.cnn_final_width, self.output_size)\n",
    "        self.init_hidden(bs)\n",
    "        #self.conv = ConvNet(out_dim=self.cnn_final_width)\n",
    "        self.conv = ConvnetBuilder(resnet18, 11, False, False).model#[:6]\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        #rnn_input = self.conv(cs).unsqueeze(1) #seq_len, batch, input_size\n",
    "        #rnn_input = F.relu(self.convToLSTM(self.flatten(self.conv(cs))), inplace=True)\n",
    "        #rnn_input = F.relu(rnn_input)\n",
    "        #rnn_input = rnn_input.unsqueeze(1)\n",
    "        \n",
    "        #outp,h = self.rnn(rnn_input, self.h)\n",
    "        #self.h = repackage_var(h)\n",
    "        \n",
    "        #------- wtf test\n",
    "        #print(cs.shape)\n",
    "        x = self.conv(cs)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        out = F.log_softmax(x, dim=-1)\n",
    "        #print(out)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        #return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.output_size)\n",
    "        #return F.log_softmax(self.final_out(rnn_input), dim=-1).view(-1, self.output_size)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        #self.h = (V(torch.zeros(self.number_rnn_layers, bs, self.rnn_hidden_count)),\n",
    "        #          V(torch.zeros(self.number_rnn_layers, bs, self.rnn_hidden_count)))\n",
    "        self.h = (V(torch.zeros(1, 1, self.rnn_hidden_count)),\n",
    "                  V(torch.zeros(1, 1, self.rnn_hidden_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "myLSTM = SingleModel(PasswordStatefulLSTM(bs).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faux_loss(preds, target):\n",
    "    #print(preds, target)\n",
    "    return F.nll_loss(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(md, myLSTM, opt_fn=optim.SGD, crit=faux_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f129caed4a5942cf953fcd7b55eac9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      nan        nan        0.1       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(1e-2, 1, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
